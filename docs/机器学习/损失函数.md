# 损失函数



::: tip 什么是损失函数？

损失函数（Loss Function）则是这个过程中关键的一个组成部分，用来**衡量模型的输出与真实的**之间的差距，给模型的优化指明方向。

:::



​		在讲损失函数之前，我们需要先理清楚损失函数、代价函数、目标函数这三者之间的区别。

- \- [损失函数](https://so.csdn.net/so/search?q=损失函数&spm=1001.2101.3001.7020) Loss Function 通常是**针对单个训练样本而言**，给定一个模型输出和一个真实 ，损失函数输出一个实值损失 
- \- 代价函数 Cost Function 通常是**针对整个训练集**（或者在使用 mini-batch gradient descent 时一个 mini-batch）的总损失 
- \- 目标函数 Objective Function 是一个更通用的术语，表示任意希望被优化的函数，用于机器学习领域和非机器学习领域（比如运筹优化）

<mark>一句话总结三者的关系就是：A loss function is a part of a cost function which is a type of an objective function.</mark>

## 1 MSE均方损失函数

​		MSE也叫做L2 loss；

​		是**回归任务**中常用的一个损失函数

![0922b69611ef2ea0132a8c9ddacaf0ce.png](https://s2.loli.net/2022/05/28/MsvVX2xq5KoFRzH.png)



## 2 平均绝对损失函数

​		MAE（mean absolute error），也叫L1 loss；

​		适用于回归任务

![cb83165e0feefa450881a153240dd9b8.png](https://s2.loli.net/2022/05/28/btwsDN96MdR7SxT.png)



### MAE 与 MSE 区别

​		MAE 和 MSE 作为损失函数的主要区别是：MSE 损失相比 MAE 通常可以更快地收敛，但 MAE 损失对于 outlier 更加健壮，即更加不易受到 outlier 影响。

1. **MSE 通常比 MAE 可以更快地收敛**。当使用梯度下降算法时，MSE 损失的梯度为 ，而 MAE 损失的梯度为 ，即 MSE 的梯度的 scale 会随误差大小变化，而 MAE 的梯度的 scale 则一直保持为 1，即便在绝对误差 很小的时候 MAE 的梯度 scale 也同样为 1，这实际上是非常不利于模型的训练的。当然你可以通过在训练过程中动态调整学习率缓解这个问题，但是总的来说，损失函数梯度之间的差异导致了 MSE 在大部分时候比 MAE 收敛地更快。这个也是 MSE 更为流行的原因。
2. **MAE 对于 outlier 更加 robust**。我们可以从两个角度来理解这一点：第一个角度是直观地理解，下图是 MAE 和 MSE 损失画到同一张图里面，由于MAE 损失与绝对误差之间是线性关系，MSE 损失与误差是平方关系，当误差非常大的时候，MSE 损失会远远大于 MAE 损失。因此当数据中出现一个误差非常大的 outlier 时，MSE 会产生一个非常大的损失，对模型的训练会产生较大的影响。



## 3 交叉熵损失函数

​		对于**分类问题**，最常用的损失函数是交叉熵损失函数 Cross Entropy Loss



### 二分类问题

​		我们经常使用sigmoid函数，将模型的输出压缩到 (0, 1) 区间内 ，用来代表给定输入 ，模型判断为正类的概率。由于只有正负两类，因此同时也得到了负类的概率。





### 多分类问题



​		我们对于多分类问题，通常使用softmax函数。

​		通常对于预测的结果值，我们用one-hot编码来表示。

​		通常这个应用于多分类的交叉熵损失函数也被称为 Softmax Loss 或者 Categorical Cross Entropy Loss



<img src="C:/Users/Jacky/AppData/Roaming/Typora/typora-user-images/image-20220528200458902.png" alt="image-20220528200458902" style="zoom:50%;" />