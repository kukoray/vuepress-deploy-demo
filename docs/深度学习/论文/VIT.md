# VIT

Transformer架构的图像分类模型。VIT最初由Google Brain团队在2020年提出，其主要思想是将图像看作是一个序列，然后将其送入Transformer模型进行处理。

VIT使用了一种叫做“图像块划分”（image patching）的技术，将图像分成若干个大小相同的块，每个块都被视为一个序列元素。然后，VIT使用Transformer的编码器来学习图像的特征表示。在编码器中，每个图像块都被视为一个输入令牌，它们通过多头自注意力机制（multi-head self-attention）和前馈神经网络（feed-forward network）等模块进行处理。

与传统的卷积神经网络（CNN）相比，VIT具有以下优势：

1. VIT可以处理任意大小的图像，而CNN则需要对图像进行预处理和调整大小。
2. VIT在处理长宽比不同的图像时更加有效，因为它将图像块视为序列元素，而不是像CNN一样将整个图像视为一个张量。
3. VIT可以捕捉全局特征和局部特征，因为它使用了Transformer的自注意力机制，使得每个图像块都可以与其他块进行交互，从而实现全局上下文的建模。