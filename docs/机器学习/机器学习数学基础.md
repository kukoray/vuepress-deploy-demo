# 机器学习数学基础



<img src="https://s2.loli.net/2022/04/26/3Zaoz12emWn4tpy.png" alt="image-20220426213634626" style="zoom:80%;" />



## 协方差

​		**协方差**（Covariance）在[概率论](https://baike.baidu.com/item/概率论/829122)和[统计学](https://baike.baidu.com/item/统计学/1175)中用于衡量两个变量的总体[误差](https://baike.baidu.com/item/误差/738024)。而[**方差**](https://baike.baidu.com/item/方差/3108412)是**协方差的一种特殊情况**，即当两个变量是相同的情况。

​		协方差表示的是两个变量的总体的[误差](https://baike.baidu.com/item/误差/738024)，这与只表示一个变量误差的[方差](https://baike.baidu.com/item/方差/3108412)不同。如果两个[变量](https://baike.baidu.com/item/变量/5271)的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。

![img](https://bkimg.cdn.bcebos.com/formula/bd5a49802fd29c7a58bbba490f66ee93.svg)

​		如果*X*与*Y*是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足*E*[*XY*]=*E*[*X*]*E*[*Y*]。









## 概率基础

[概率基础最好的文章](https://blog.csdn.net/gcheney/article/details/108442861)

### 概率和统计

- 概率：已知模型和参数（生成数据的过程），推数据（结果）。（机器学习模型的**应用**）
- 统计：已知数据，推模型和参数。（机器学习模型的**训练过程**）



### 贝叶斯公式

![image-20230407195006425](https://s2.loli.net/2023/04/07/GPIyTu5gvsaFkKO.png)

深入理解：

例子：A是车被砸，B是车发出警报

那么我们先要算的是，左式  = **车发出警报，车被砸了的可能性？**

右式  =  **【车被砸，引起警报】 除以  【车发出警报】**

**从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。你的车响了，不一定是被砸了，也有可能就是隔壁小朋友踢了一脚。**



### 似然函数和概率函数

在统计里面，似然函数(likelihood function)和概率函数(probability function)是两个不同的概念（其实也很相近就是了）。
　　
之前我们说到：
　　**概率是已知模型和参数（生成数据的过程），推数据（结果）。
　　统计是已知数据（结果），推模型和参数（生成数据的过程）。**
　　对于这个函数：P ( x ∣ θ )。输入有两个：x 表示某一个具体的数据；θ 表示模型的参数。

如果θ 是已知确定的，x 是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x ，其出现概率是多少。

如果x 是已知确定的，θ 是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现x 这个样本点的概率是多少。







### KL散度

是两个概率分布 P和Q 的相似性



### JS散度



### wasserstein距离





## 欧式空间和黎曼空间





### hessian matrix

海森矩阵

### fisher information matrix

费舍尔信息矩阵





## 凸优化问题











## SVD奇异值分解

简而言之就是：将矩阵分解为奇异向量以及奇异值
