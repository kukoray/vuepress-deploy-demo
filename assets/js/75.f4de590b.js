(window.webpackJsonp=window.webpackJsonp||[]).push([[75],{494:function(t,r,e){"use strict";e.r(r);var a=e(65),n=Object(a.a)({},(function(){var t=this,r=t.$createElement,e=t._self._c||r;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"vit"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#vit"}},[t._v("#")]),t._v(" VIT")]),t._v(" "),e("p",[t._v("Transformer架构的图像分类模型。VIT最初由Google Brain团队在2020年提出，其主要思想是将图像看作是一个序列，然后将其送入Transformer模型进行处理。")]),t._v(" "),e("p",[t._v("VIT使用了一种叫做“图像块划分”（image patching）的技术，将图像分成若干个大小相同的块，每个块都被视为一个序列元素。然后，VIT使用Transformer的编码器来学习图像的特征表示。在编码器中，每个图像块都被视为一个输入令牌，它们通过多头自注意力机制（multi-head self-attention）和前馈神经网络（feed-forward network）等模块进行处理。")]),t._v(" "),e("p",[t._v("与传统的卷积神经网络（CNN）相比，VIT具有以下优势：")]),t._v(" "),e("ol",[e("li",[t._v("VIT可以处理任意大小的图像，而CNN则需要对图像进行预处理和调整大小。")]),t._v(" "),e("li",[t._v("VIT在处理长宽比不同的图像时更加有效，因为它将图像块视为序列元素，而不是像CNN一样将整个图像视为一个张量。")]),t._v(" "),e("li",[t._v("VIT可以捕捉全局特征和局部特征，因为它使用了Transformer的自注意力机制，使得每个图像块都可以与其他块进行交互，从而实现全局上下文的建模。")])])])}),[],!1,null,null,null);r.default=n.exports}}]);