<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>CNN卷积神经网络 | JACKY</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
    <link rel="stylesheet" href="/css/index.css">
    <link rel="icon" href="/images/logo.png">
    <meta name="description" content="">
    
    <link rel="preload" href="/assets/css/0.styles.e4d8b86b.css" as="style"><link rel="preload" href="/assets/js/app.6d855320.js" as="script"><link rel="preload" href="/assets/js/2.d4ff5c60.js" as="script"><link rel="preload" href="/assets/js/56.629bc4a4.js" as="script"><link rel="prefetch" href="/assets/js/10.0677b883.js"><link rel="prefetch" href="/assets/js/100.47224151.js"><link rel="prefetch" href="/assets/js/101.e068f649.js"><link rel="prefetch" href="/assets/js/102.2216aa0a.js"><link rel="prefetch" href="/assets/js/103.1274fdb9.js"><link rel="prefetch" href="/assets/js/104.3894d45f.js"><link rel="prefetch" href="/assets/js/105.c45ae0dd.js"><link rel="prefetch" href="/assets/js/106.1ea76166.js"><link rel="prefetch" href="/assets/js/107.e9e69cdf.js"><link rel="prefetch" href="/assets/js/108.86dc789c.js"><link rel="prefetch" href="/assets/js/109.dff0ff70.js"><link rel="prefetch" href="/assets/js/11.0ce9576d.js"><link rel="prefetch" href="/assets/js/110.3a698495.js"><link rel="prefetch" href="/assets/js/111.8fc0aa53.js"><link rel="prefetch" href="/assets/js/112.aebd4f61.js"><link rel="prefetch" href="/assets/js/113.ac824a62.js"><link rel="prefetch" href="/assets/js/114.09b2f358.js"><link rel="prefetch" href="/assets/js/115.31a681fc.js"><link rel="prefetch" href="/assets/js/116.2eb333c2.js"><link rel="prefetch" href="/assets/js/117.45d3427d.js"><link rel="prefetch" href="/assets/js/118.313f7765.js"><link rel="prefetch" href="/assets/js/119.985d374f.js"><link rel="prefetch" href="/assets/js/12.809e25a2.js"><link rel="prefetch" href="/assets/js/120.41447dc4.js"><link rel="prefetch" href="/assets/js/121.f014baf8.js"><link rel="prefetch" href="/assets/js/122.097f6079.js"><link rel="prefetch" href="/assets/js/123.afc6a702.js"><link rel="prefetch" href="/assets/js/124.01d724f7.js"><link rel="prefetch" href="/assets/js/125.c9dc4beb.js"><link rel="prefetch" href="/assets/js/126.d5b795cb.js"><link rel="prefetch" href="/assets/js/127.ca74f94d.js"><link rel="prefetch" href="/assets/js/128.d2da9329.js"><link rel="prefetch" href="/assets/js/129.c8717ca5.js"><link rel="prefetch" href="/assets/js/13.152c7e44.js"><link rel="prefetch" href="/assets/js/14.1e51776e.js"><link rel="prefetch" href="/assets/js/15.baa617fb.js"><link rel="prefetch" href="/assets/js/16.f85fffe6.js"><link rel="prefetch" href="/assets/js/17.e6803744.js"><link rel="prefetch" href="/assets/js/18.6d74ca46.js"><link rel="prefetch" href="/assets/js/19.ab7532ab.js"><link rel="prefetch" href="/assets/js/20.be01556b.js"><link rel="prefetch" href="/assets/js/21.d9aded00.js"><link rel="prefetch" href="/assets/js/22.59fd96e2.js"><link rel="prefetch" href="/assets/js/23.575b0571.js"><link rel="prefetch" href="/assets/js/24.d7911b48.js"><link rel="prefetch" href="/assets/js/25.ee1ddc47.js"><link rel="prefetch" href="/assets/js/26.2645d0d2.js"><link rel="prefetch" href="/assets/js/27.b445999f.js"><link rel="prefetch" href="/assets/js/28.e93df91c.js"><link rel="prefetch" href="/assets/js/29.2e9e94e3.js"><link rel="prefetch" href="/assets/js/3.cce6fa70.js"><link rel="prefetch" href="/assets/js/30.c46c1576.js"><link rel="prefetch" href="/assets/js/31.d700821d.js"><link rel="prefetch" href="/assets/js/32.4017f172.js"><link rel="prefetch" href="/assets/js/33.c2f92eee.js"><link rel="prefetch" href="/assets/js/34.384d918e.js"><link rel="prefetch" href="/assets/js/35.9c122bb0.js"><link rel="prefetch" href="/assets/js/36.4ee62a31.js"><link rel="prefetch" href="/assets/js/37.cc538cd0.js"><link rel="prefetch" href="/assets/js/38.66fe6d97.js"><link rel="prefetch" href="/assets/js/39.62865922.js"><link rel="prefetch" href="/assets/js/4.ba8c4904.js"><link rel="prefetch" href="/assets/js/40.18d8b6ea.js"><link rel="prefetch" href="/assets/js/41.df0d8cab.js"><link rel="prefetch" href="/assets/js/42.2c76aec4.js"><link rel="prefetch" href="/assets/js/43.35b2ed84.js"><link rel="prefetch" href="/assets/js/44.7832dc93.js"><link rel="prefetch" href="/assets/js/45.bda8de55.js"><link rel="prefetch" href="/assets/js/46.6dfbc71d.js"><link rel="prefetch" href="/assets/js/47.ce3854ed.js"><link rel="prefetch" href="/assets/js/48.a0914b71.js"><link rel="prefetch" href="/assets/js/49.f409f02c.js"><link rel="prefetch" href="/assets/js/5.ebbfaeab.js"><link rel="prefetch" href="/assets/js/50.4f56073a.js"><link rel="prefetch" href="/assets/js/51.876c612d.js"><link rel="prefetch" href="/assets/js/52.d1cb790e.js"><link rel="prefetch" href="/assets/js/53.0e7bdacf.js"><link rel="prefetch" href="/assets/js/54.69554266.js"><link rel="prefetch" href="/assets/js/55.e91b1adb.js"><link rel="prefetch" href="/assets/js/57.dd0e1f38.js"><link rel="prefetch" href="/assets/js/58.6210b964.js"><link rel="prefetch" href="/assets/js/59.3171311f.js"><link rel="prefetch" href="/assets/js/6.319d6800.js"><link rel="prefetch" href="/assets/js/60.f28df51c.js"><link rel="prefetch" href="/assets/js/61.9d91b4cf.js"><link rel="prefetch" href="/assets/js/62.64dca654.js"><link rel="prefetch" href="/assets/js/63.2422c5f1.js"><link rel="prefetch" href="/assets/js/64.2a1e3d2b.js"><link rel="prefetch" href="/assets/js/65.f58499a8.js"><link rel="prefetch" href="/assets/js/66.c0efeb82.js"><link rel="prefetch" href="/assets/js/67.661d7923.js"><link rel="prefetch" href="/assets/js/68.dfab90f4.js"><link rel="prefetch" href="/assets/js/69.d9aed373.js"><link rel="prefetch" href="/assets/js/7.b1af566c.js"><link rel="prefetch" href="/assets/js/70.42a55bd7.js"><link rel="prefetch" href="/assets/js/71.26f59ddc.js"><link rel="prefetch" href="/assets/js/72.08c4a8c5.js"><link rel="prefetch" href="/assets/js/73.3f37d91a.js"><link rel="prefetch" href="/assets/js/74.e351145c.js"><link rel="prefetch" href="/assets/js/75.f4de590b.js"><link rel="prefetch" href="/assets/js/76.67c626c7.js"><link rel="prefetch" href="/assets/js/77.f1130886.js"><link rel="prefetch" href="/assets/js/78.778d639c.js"><link rel="prefetch" href="/assets/js/79.86f9f4d3.js"><link rel="prefetch" href="/assets/js/8.3b56d639.js"><link rel="prefetch" href="/assets/js/80.4ee16963.js"><link rel="prefetch" href="/assets/js/81.01badefa.js"><link rel="prefetch" href="/assets/js/82.4613395c.js"><link rel="prefetch" href="/assets/js/83.03b7e3d1.js"><link rel="prefetch" href="/assets/js/84.a8ed7238.js"><link rel="prefetch" href="/assets/js/85.d0a23cae.js"><link rel="prefetch" href="/assets/js/86.47c348c3.js"><link rel="prefetch" href="/assets/js/87.7103da76.js"><link rel="prefetch" href="/assets/js/88.03092892.js"><link rel="prefetch" href="/assets/js/89.9e2e01ba.js"><link rel="prefetch" href="/assets/js/9.1ad63360.js"><link rel="prefetch" href="/assets/js/90.bc109fb6.js"><link rel="prefetch" href="/assets/js/91.edd4ee6f.js"><link rel="prefetch" href="/assets/js/92.47eef26d.js"><link rel="prefetch" href="/assets/js/93.f3dd468d.js"><link rel="prefetch" href="/assets/js/94.5928d8ae.js"><link rel="prefetch" href="/assets/js/95.a7a96583.js"><link rel="prefetch" href="/assets/js/96.b8df9976.js"><link rel="prefetch" href="/assets/js/97.3200a463.js"><link rel="prefetch" href="/assets/js/98.29d61ae7.js"><link rel="prefetch" href="/assets/js/99.25ff9892.js">
    <link rel="stylesheet" href="/assets/css/0.styles.e4d8b86b.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">JACKY</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <!----></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><!---->  <ul class="sidebar-links"><li><a href="/" aria-current="page" class="sidebar-link">/</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Linux操作系统</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>专业课</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>机器学习</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>深度学习</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/深度学习/CNN.html" class="active sidebar-link">CNN卷积神经网络</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#cnn" class="sidebar-link">CNN</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#卷积层" class="sidebar-link">卷积层</a></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#池化层" class="sidebar-link">池化层</a></li></ul></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#_3dcnn" class="sidebar-link">3DCNN</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#硬线层" class="sidebar-link">硬线层</a></li></ul></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#shortcut" class="sidebar-link">Shortcut</a></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#cnn常见问题" class="sidebar-link">CNN常见问题</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#_1-1卷积为什么能降维" class="sidebar-link">1*1卷积为什么能降维？</a></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#网络退化问题" class="sidebar-link">网络退化问题？</a></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#为什么残差连接能解决网络退化问题" class="sidebar-link">为什么残差连接能解决网络退化问题？</a></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#高斯金字塔" class="sidebar-link">高斯金字塔</a></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#拉普拉斯金字塔" class="sidebar-link">拉普拉斯金字塔</a></li></ul></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#_1特征提取" class="sidebar-link">1特征提取</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#_1-1形状特征" class="sidebar-link">1.1形状特征</a></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#_1-2纹理特征" class="sidebar-link">1.2纹理特征</a></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#_1-3-颜色特征" class="sidebar-link">1.3 颜色特征</a></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#_1-4-空间关系特征" class="sidebar-link">1.4 空间关系特征</a></li></ul></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#dw卷积" class="sidebar-link">DW卷积</a></li><li class="sidebar-sub-header"><a href="/深度学习/CNN.html#卷积基本训练代码" class="sidebar-link">卷积基本训练代码</a></li></ul></li><li><a href="/深度学习/ImageNet.html" class="sidebar-link">ImageNet</a></li><li><a href="/深度学习/RNN.html" class="sidebar-link">RNN</a></li><li><a href="/深度学习/SSD.html" class="sidebar-link">SSD目标检测</a></li><li><a href="/深度学习/manifold.html" class="sidebar-link">流形 Manifold</a></li><li><a href="/深度学习/优化器.html" class="sidebar-link">优化器</a></li><li><a href="/深度学习/归一化.html" class="sidebar-link">归一化方法</a></li><li><a href="/深度学习/数字图像处理.html" class="sidebar-link">数字图像处理</a></li><li><a href="/深度学习/欧拉增强的心率检测.html" class="sidebar-link">eulerian heartrate detection</a></li><li><a href="/深度学习/深度学习常见问题.html" class="sidebar-link">常见问题</a></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>论文</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>硬件设计</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>算法与数据结构</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>编程语言</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>联邦学习</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>软件开发</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="cnn卷积神经网络"><a href="#cnn卷积神经网络" class="header-anchor">#</a> CNN卷积神经网络</h1> <p><img src="https://s2.loli.net/2022/05/17/tzLbE6uHT1QGM7D.png" alt="这里写图片描述"></p> <h2 id="cnn"><a href="#cnn" class="header-anchor">#</a> CNN</h2> <p>卷积层还有一个特性就是“权值共享”原则。</p> <h3 id="卷积层"><a href="#卷积层" class="header-anchor">#</a> 卷积层</h3> <p><img src="https://s2.loli.net/2023/07/24/GBgez9ambAVN713.webp" alt="img"></p> <p>卷积层：输入的数据也叫特征feature map，维度一般是 channel * long * width 例如 256x224x224</p> <p>卷积层输出的数据特征维度是  512x111x111</p> <p>其中这里的512是指filter的个数，这里的filter在多通道的卷积中是卷积核的集合，例如此处，一个filter的大小就是256x3x3</p> <p>个数是512个，所以整个卷积层的参数是 512x256x3x3</p> <p><strong>卷积的计算公式</strong></p> <p>卷积神将网络的计算公式为：
<strong>N=(W-F+2P)/S+1</strong></p> <blockquote><p>其中N：输出大小
W：输入大小
F：<a href="https://so.csdn.net/so/search?q=%E5%8D%B7%E7%A7%AF%E6%A0%B8&amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener noreferrer">卷积核<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>大小
P：填充值的大小
S：步长大小</p></blockquote> <p><img src="https://s2.loli.net/2023/07/24/oQLzIy1xewZ3b6F.png" alt="image-20230724170016656"></p> <h3 id="池化层"><a href="#池化层" class="header-anchor">#</a> 池化层</h3> <p>也叫下采样层，缩小feature map 的大小</p> <p><strong>该层没有任何参数</strong>，只有size（3x3）和stride（步长为2）；</p> <p>常用:</p> <blockquote><p>maxPooling：最大池化，把3*3的区域里最大值作为该区域的代表，起到突出的效果</p> <p>averagePooling：平均池化，把3*3区域的平均值作为该区域代表，起到模糊的效果</p></blockquote> <p>图中不同颜色代表不同的特征，需要学习对应数量的卷积核进行<a href="https://so.csdn.net/so/search?q=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener noreferrer">特征提取<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <p>对于<a href="https://so.csdn.net/so/search?q=%E7%81%B0%E5%BA%A6%E5%9B%BE%E5%83%8F&amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener noreferrer">灰度图像<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，图像为2D
例如一个图像大小是5×5，
有一个3×3的卷积核对着图像进行卷积，步长为1，卷积结束后生成一个3×3的矩阵。
如果有2组卷积核对着图像卷积，就会生成2个3×3的矩阵。
<strong>同理有多少组卷积核对图像卷积就有多少个矩阵。</strong>
这个叫做通道。</p> <p>对于RGB图像，图像为3维
若要提取2个特征，可以设置2个3维卷积核进行特征提取，提取结果为2通道的feature map，2个通道互相独立，代表着不同卷积核提取的不同特征。</p> <img src="https://img-blog.csdnimg.cn/20210715191700154.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tyaXNfcGF1bA==,size_16,color_FFFFFF,t_70" alt="sad" style="zoom:70%;"> <p><a href="https://cs231n.github.io/assets/conv-demo/index.html" target="_blank" rel="noopener noreferrer">上图的动图链接<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><strong>一般来说一个卷积核对应着一个特征的提取</strong>（例如：一个卷积核用来提取边缘特征，另外一个卷积核用来提取x方向的边缘特征等）</p> <p><strong>进行卷积处理的卷积通道数默认和输入图像的通道数相等。</strong>
比如输入图像维度为256，进行特征提取的卷积核也默认是256维。
若设定输出64个特征，那么就一共有64个256维的卷积核用来提取特征，即提取特征的输出通道数为64，输出64个feature map。</p> <img src="https://img-blog.csdnimg.cn/20210715191734669.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tyaXNfcGF1bA==,size_16,color_FFFFFF,t_70" alt="im g" style="zoom:33%;"> <h2 id="_3dcnn"><a href="#_3dcnn" class="header-anchor">#</a> 3DCNN</h2> <h3 id="硬线层"><a href="#硬线层" class="header-anchor">#</a> 硬线层</h3> <p>每帧提取5个通道信息（gray、gradient_X、gradient_Y、optflow_X、optflow_Y）</p> <h2 id="shortcut"><a href="#shortcut" class="header-anchor">#</a> Shortcut</h2> <p>残差块，也叫skip connect，</p> <h2 id="cnn常见问题"><a href="#cnn常见问题" class="header-anchor">#</a> CNN常见问题</h2> <h3 id="_1-1卷积为什么能降维"><a href="#_1-1卷积为什么能降维" class="header-anchor">#</a> 1*1卷积为什么能降维？</h3> <p>背景：最早出现在 Network In Network的论文中 ，使用1*1卷积是想<strong>加深加宽网络结构</strong> 。</p> <p>所谓1x1默认是w和h上的1x1，但对于高维度，其实应该是这样：就是H和W不变，而是channel这个维度上降维，如图对于channel与原三维矩阵相同的1x1卷积核，直接channel就给干到了1维，而原来是32维。</p> <p>1*1卷积的主要作用有以下几点：</p> <p>1、降维。比如，<strong>一张500 x 500且厚度depth为100 的图片在20个filter上做1x1的卷积，那么结果的大小为500x500x20。</strong></p> <p>2、加入非线性。卷积层之后经过激励层，1*1的卷积在前一层的学习表示上添加了非线性激励，提升网络的表达能力；</p> <p>3、增加模型深度。可以减少网络模型参数，增加网络层深度，一定程度上提升模型的表征能力。</p> <h3 id="网络退化问题"><a href="#网络退化问题" class="header-anchor">#</a> 网络退化问题？</h3> <p>​		举个例子，假设已经有了一个最优化的网络结构，是18层。当我们设计网络结构的时候，我们并不知道具体多少层次的网络是最优化的网络结构，假设设计了34层网络结构。那么多出来的16层其实是冗余的，我们希望训练网络的过程中，模型能够自己训练这五层为恒等映射，也就是经过这层时的输入与输出完全一样。</p> <p>​		但是往往模型很难将这16层恒等映射的参数学习正确，那么就一定会不比最优化的18层网络结构性能好，这就是<strong>随着网络深度增加，模型会产生退化现象</strong>。它不是由过拟合产生的，而是由<strong>冗余的网络层学习了不是恒等映射的参数</strong>造成的。</p> <h3 id="为什么残差连接能解决网络退化问题"><a href="#为什么残差连接能解决网络退化问题" class="header-anchor">#</a> 为什么残差连接能解决网络退化问题？</h3> <p>我们发现，要想让该冗余层能够恒等映射，我们只需要学习F(x)=0。<strong>学习F(x)=0比学习h(x)=x要简单，因为一般每层网络中的参数初始化偏向于0</strong>，这样在相比于更新该网络层的参数来学习h(x)=x，该冗余层学习F(x)=0的更新参数能够更快收敛</p> <p>并且ReLU能够将负数激活为0，过滤了负数的线性变化，也能够更快的使得F(x)=0。这样当网络自己决定哪些网络层为冗余层时，使用ResNet的网络很大程度上解决了学习恒等映射的问题，用学习残差F(x)=0更新该冗余层的参数来代替学习h(x)=x更新冗余层的参数。</p> <h3 id="高斯金字塔"><a href="#高斯金字塔" class="header-anchor">#</a> 高斯金字塔</h3> <p><img src="https://s2.loli.net/2022/05/25/jnNoLmtCz3S9WdO.jpg" alt="img"></p> <p>高斯金字塔，本质就是在原图片的基础上，进行高斯模糊（一个滤波器，filter，其实就是一个卷积核），然后进行2*2的下采样。</p> <p>得到了同一张图片不同尺度的子图。</p> <h3 id="拉普拉斯金字塔"><a href="#拉普拉斯金字塔" class="header-anchor">#</a> 拉普拉斯金字塔</h3> <p>拉普拉斯金字塔可以认为就是一个残差金字塔。</p> <img src="https://s2.loli.net/2022/05/26/Kmf25XAeBlVhbtW.png" alt="img" style="zoom:50%;"> <p>我们知道一张图片进行下采样后，在进行上采样，图片是没办法恢复的一模一样的，也就是说下采样是一个不可逆的过程。</p> <p><img src="https://pic2.zhimg.com/80/v2-cd004410f46aa5657a946568ff403251_720w.jpg" alt="im g"></p> <p>可以看出，原始图片下采样后得到的小尺寸图片虽然保留了视觉效果，但是将该小尺寸图像再次上采样也不能完整的恢复出原始图像。为了能够从下采样图像Down(Gi)中还原原始图像Gi，我们需要记<strong>录再次上采样得到Up(Down(Gi))与原始图片Gi之间的差异</strong>，这就是拉普拉斯金字塔的核心思想</p> <p><img src="https://pic3.zhimg.com/80/v2-1641deeb3eec372b6ff3fc436c8651b6_720w.jpg" alt="img"></p> <p>下面的就是<strong>拉普拉斯金字塔</strong></p> <p><img src="https://pic3.zhimg.com/80/v2-d88c440419db98a262482d31b4a19e22_720w.jpg" alt="img"></p> <h2 id="_1特征提取"><a href="#_1特征提取" class="header-anchor">#</a> 1特征提取</h2> <h3 id="_1-1形状特征"><a href="#_1-1形状特征" class="header-anchor">#</a> 1.1形状特征</h3> <h4 id="_1-1-1-hog"><a href="#_1-1-1-hog" class="header-anchor">#</a> 1.1.1 HOG</h4> <p>HOG主要是用于提取图片的一个形状特征，经常用HOG+SVM的方式来进行行人检测。</p> <h4 id="_1-1-2-sift"><a href="#_1-1-2-sift" class="header-anchor">#</a> 1.1.2 SIFT</h4> <h4 id="_1-1-3-harris"><a href="#_1-1-3-harris" class="header-anchor">#</a> 1.1.3 Harris</h4> <h3 id="_1-2纹理特征"><a href="#_1-2纹理特征" class="header-anchor">#</a> 1.2纹理特征</h3> <h4 id="_1-2-1-lbp"><a href="#_1-2-1-lbp" class="header-anchor">#</a> 1.2.1 LBP</h4> <h3 id="_1-3-颜色特征"><a href="#_1-3-颜色特征" class="header-anchor">#</a> 1.3 颜色特征</h3> <h3 id="_1-4-空间关系特征"><a href="#_1-4-空间关系特征" class="header-anchor">#</a> 1.4 空间关系特征</h3> <h2 id="dw卷积"><a href="#dw卷积" class="header-anchor">#</a> DW卷积</h2> <p>也叫做深度可分离卷积，Separable Convolution的卷积运算方式。它将传统卷积分解为<strong>Depthwise Convolution</strong>与<strong>Pointwise Convolution</strong>两部分，有效的减小了参数数量。</p> <p><a href="https://yinguobing.com/separable-convolution/#fn2" target="_blank" rel="noopener noreferrer">卷积神经网络中的Separable Convolution (yinguobing.com)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>相同的输入，同样是得到4张Feature map，Separable Convolution的参数个数是常规卷积的约1/3。因此，在参数量相同的前提下，采用Separable Convolution的神经网络层数可以做的更深。</p> <h2 id="卷积基本训练代码"><a href="#卷积基本训练代码" class="header-anchor">#</a> 卷积基本训练代码</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment">#!/usr/bin/env python</span>
<span class="token comment"># -*- coding: UTF-8 -*-</span>
<span class="token triple-quoted-string string">'''
@Project ：slimmable_networks 
@File    ：train_BN.py
@Author  ：Jacky
@Date    ：2023-06-01 20:09 
'''</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">as</span> datasets
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">import</span> time
<span class="token keyword">import</span> ssl
ssl<span class="token punctuation">.</span>_create_default_https_context <span class="token operator">=</span> ssl<span class="token punctuation">.</span>_create_unverified_context

<span class="token comment"># 定义卷积神经网络</span>
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span> <span class="token operator">*</span> <span class="token number">16</span> <span class="token operator">*</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span> <span class="token operator">*</span> <span class="token number">16</span> <span class="token operator">*</span> <span class="token number">16</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

<span class="token comment"># 加载CIFAR-10数据集</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
trainset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data/cifar10'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
trainloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 定义模型、损失函数和优化器</span>
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>trainloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">99</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d, %5d] loss: %.3f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> running_loss <span class="token operator">/</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            running_loss <span class="token operator">=</span> <span class="token number">0.0</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training. Time taken:'</span><span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time<span class="token punctuation">,</span> <span class="token string">'seconds'</span><span class="token punctuation">)</span>
</code></pre></div></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">最后更新时间:</span> <span class="time">1 分钟前</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/机器学习/MachineLearningNotes-master/cheatsheet.html" class="prev">
        总结
      </a></span> <span class="next"><a href="/深度学习/ImageNet.html">
        ImageNet
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.6d855320.js" defer></script><script src="/assets/js/2.d4ff5c60.js" defer></script><script src="/assets/js/56.629bc4a4.js" defer></script>
  </body>
</html>
