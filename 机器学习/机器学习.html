<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>ML入门 | JACKY</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
    <link rel="stylesheet" href="/css/index.css">
    <link rel="icon" href="/images/logo.png">
    <meta name="description" content="">
    
    <link rel="preload" href="/assets/css/0.styles.e4d8b86b.css" as="style"><link rel="preload" href="/assets/js/app.6d855320.js" as="script"><link rel="preload" href="/assets/js/2.d4ff5c60.js" as="script"><link rel="preload" href="/assets/js/52.d1cb790e.js" as="script"><link rel="prefetch" href="/assets/js/10.0677b883.js"><link rel="prefetch" href="/assets/js/100.47224151.js"><link rel="prefetch" href="/assets/js/101.e068f649.js"><link rel="prefetch" href="/assets/js/102.2216aa0a.js"><link rel="prefetch" href="/assets/js/103.1274fdb9.js"><link rel="prefetch" href="/assets/js/104.3894d45f.js"><link rel="prefetch" href="/assets/js/105.c45ae0dd.js"><link rel="prefetch" href="/assets/js/106.1ea76166.js"><link rel="prefetch" href="/assets/js/107.e9e69cdf.js"><link rel="prefetch" href="/assets/js/108.86dc789c.js"><link rel="prefetch" href="/assets/js/109.dff0ff70.js"><link rel="prefetch" href="/assets/js/11.0ce9576d.js"><link rel="prefetch" href="/assets/js/110.3a698495.js"><link rel="prefetch" href="/assets/js/111.8fc0aa53.js"><link rel="prefetch" href="/assets/js/112.aebd4f61.js"><link rel="prefetch" href="/assets/js/113.ac824a62.js"><link rel="prefetch" href="/assets/js/114.09b2f358.js"><link rel="prefetch" href="/assets/js/115.31a681fc.js"><link rel="prefetch" href="/assets/js/116.2eb333c2.js"><link rel="prefetch" href="/assets/js/117.45d3427d.js"><link rel="prefetch" href="/assets/js/118.313f7765.js"><link rel="prefetch" href="/assets/js/119.985d374f.js"><link rel="prefetch" href="/assets/js/12.809e25a2.js"><link rel="prefetch" href="/assets/js/120.41447dc4.js"><link rel="prefetch" href="/assets/js/121.f014baf8.js"><link rel="prefetch" href="/assets/js/122.097f6079.js"><link rel="prefetch" href="/assets/js/123.afc6a702.js"><link rel="prefetch" href="/assets/js/124.01d724f7.js"><link rel="prefetch" href="/assets/js/125.c9dc4beb.js"><link rel="prefetch" href="/assets/js/126.d5b795cb.js"><link rel="prefetch" href="/assets/js/127.ca74f94d.js"><link rel="prefetch" href="/assets/js/128.d2da9329.js"><link rel="prefetch" href="/assets/js/129.c8717ca5.js"><link rel="prefetch" href="/assets/js/13.152c7e44.js"><link rel="prefetch" href="/assets/js/14.1e51776e.js"><link rel="prefetch" href="/assets/js/15.baa617fb.js"><link rel="prefetch" href="/assets/js/16.f85fffe6.js"><link rel="prefetch" href="/assets/js/17.e6803744.js"><link rel="prefetch" href="/assets/js/18.6d74ca46.js"><link rel="prefetch" href="/assets/js/19.ab7532ab.js"><link rel="prefetch" href="/assets/js/20.be01556b.js"><link rel="prefetch" href="/assets/js/21.d9aded00.js"><link rel="prefetch" href="/assets/js/22.59fd96e2.js"><link rel="prefetch" href="/assets/js/23.575b0571.js"><link rel="prefetch" href="/assets/js/24.d7911b48.js"><link rel="prefetch" href="/assets/js/25.ee1ddc47.js"><link rel="prefetch" href="/assets/js/26.2645d0d2.js"><link rel="prefetch" href="/assets/js/27.b445999f.js"><link rel="prefetch" href="/assets/js/28.e93df91c.js"><link rel="prefetch" href="/assets/js/29.2e9e94e3.js"><link rel="prefetch" href="/assets/js/3.cce6fa70.js"><link rel="prefetch" href="/assets/js/30.c46c1576.js"><link rel="prefetch" href="/assets/js/31.d700821d.js"><link rel="prefetch" href="/assets/js/32.4017f172.js"><link rel="prefetch" href="/assets/js/33.c2f92eee.js"><link rel="prefetch" href="/assets/js/34.384d918e.js"><link rel="prefetch" href="/assets/js/35.9c122bb0.js"><link rel="prefetch" href="/assets/js/36.4ee62a31.js"><link rel="prefetch" href="/assets/js/37.cc538cd0.js"><link rel="prefetch" href="/assets/js/38.66fe6d97.js"><link rel="prefetch" href="/assets/js/39.62865922.js"><link rel="prefetch" href="/assets/js/4.ba8c4904.js"><link rel="prefetch" href="/assets/js/40.18d8b6ea.js"><link rel="prefetch" href="/assets/js/41.df0d8cab.js"><link rel="prefetch" href="/assets/js/42.2c76aec4.js"><link rel="prefetch" href="/assets/js/43.35b2ed84.js"><link rel="prefetch" href="/assets/js/44.7832dc93.js"><link rel="prefetch" href="/assets/js/45.bda8de55.js"><link rel="prefetch" href="/assets/js/46.6dfbc71d.js"><link rel="prefetch" href="/assets/js/47.ce3854ed.js"><link rel="prefetch" href="/assets/js/48.a0914b71.js"><link rel="prefetch" href="/assets/js/49.f409f02c.js"><link rel="prefetch" href="/assets/js/5.ebbfaeab.js"><link rel="prefetch" href="/assets/js/50.4f56073a.js"><link rel="prefetch" href="/assets/js/51.876c612d.js"><link rel="prefetch" href="/assets/js/53.0e7bdacf.js"><link rel="prefetch" href="/assets/js/54.69554266.js"><link rel="prefetch" href="/assets/js/55.e91b1adb.js"><link rel="prefetch" href="/assets/js/56.629bc4a4.js"><link rel="prefetch" href="/assets/js/57.dd0e1f38.js"><link rel="prefetch" href="/assets/js/58.6210b964.js"><link rel="prefetch" href="/assets/js/59.3171311f.js"><link rel="prefetch" href="/assets/js/6.319d6800.js"><link rel="prefetch" href="/assets/js/60.f28df51c.js"><link rel="prefetch" href="/assets/js/61.9d91b4cf.js"><link rel="prefetch" href="/assets/js/62.64dca654.js"><link rel="prefetch" href="/assets/js/63.2422c5f1.js"><link rel="prefetch" href="/assets/js/64.2a1e3d2b.js"><link rel="prefetch" href="/assets/js/65.f58499a8.js"><link rel="prefetch" href="/assets/js/66.c0efeb82.js"><link rel="prefetch" href="/assets/js/67.661d7923.js"><link rel="prefetch" href="/assets/js/68.dfab90f4.js"><link rel="prefetch" href="/assets/js/69.d9aed373.js"><link rel="prefetch" href="/assets/js/7.b1af566c.js"><link rel="prefetch" href="/assets/js/70.42a55bd7.js"><link rel="prefetch" href="/assets/js/71.26f59ddc.js"><link rel="prefetch" href="/assets/js/72.08c4a8c5.js"><link rel="prefetch" href="/assets/js/73.3f37d91a.js"><link rel="prefetch" href="/assets/js/74.e351145c.js"><link rel="prefetch" href="/assets/js/75.f4de590b.js"><link rel="prefetch" href="/assets/js/76.67c626c7.js"><link rel="prefetch" href="/assets/js/77.f1130886.js"><link rel="prefetch" href="/assets/js/78.778d639c.js"><link rel="prefetch" href="/assets/js/79.86f9f4d3.js"><link rel="prefetch" href="/assets/js/8.3b56d639.js"><link rel="prefetch" href="/assets/js/80.4ee16963.js"><link rel="prefetch" href="/assets/js/81.01badefa.js"><link rel="prefetch" href="/assets/js/82.4613395c.js"><link rel="prefetch" href="/assets/js/83.03b7e3d1.js"><link rel="prefetch" href="/assets/js/84.a8ed7238.js"><link rel="prefetch" href="/assets/js/85.d0a23cae.js"><link rel="prefetch" href="/assets/js/86.47c348c3.js"><link rel="prefetch" href="/assets/js/87.7103da76.js"><link rel="prefetch" href="/assets/js/88.03092892.js"><link rel="prefetch" href="/assets/js/89.9e2e01ba.js"><link rel="prefetch" href="/assets/js/9.1ad63360.js"><link rel="prefetch" href="/assets/js/90.bc109fb6.js"><link rel="prefetch" href="/assets/js/91.edd4ee6f.js"><link rel="prefetch" href="/assets/js/92.47eef26d.js"><link rel="prefetch" href="/assets/js/93.f3dd468d.js"><link rel="prefetch" href="/assets/js/94.5928d8ae.js"><link rel="prefetch" href="/assets/js/95.a7a96583.js"><link rel="prefetch" href="/assets/js/96.b8df9976.js"><link rel="prefetch" href="/assets/js/97.3200a463.js"><link rel="prefetch" href="/assets/js/98.29d61ae7.js"><link rel="prefetch" href="/assets/js/99.25ff9892.js">
    <link rel="stylesheet" href="/assets/css/0.styles.e4d8b86b.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">JACKY</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <!----></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><!---->  <ul class="sidebar-links"><li><a href="/" aria-current="page" class="sidebar-link">/</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Linux操作系统</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>专业课</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>机器学习</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/机器学习/EM算法.html" class="sidebar-link">EM算法</a></li><li><a href="/机器学习/K近邻.html" class="sidebar-link">K-means</a></li><li><a href="/机器学习/NLP.html" class="sidebar-link">自然语言处理</a></li><li><a href="/机器学习/PCA.html" class="sidebar-link">PCA</a></li><li><a href="/机器学习/XGBoost.html" class="sidebar-link">XGBoost</a></li><li><a href="/机器学习/决策树.html" class="sidebar-link">决策树</a></li><li><a href="/机器学习/感知机.html" class="sidebar-link">感知机</a></li><li><a href="/机器学习/损失函数.html" class="sidebar-link">损失函数</a></li><li><a href="/机器学习/支持向量机.html" class="sidebar-link">SVM</a></li><li><a href="/机器学习/数据处理.html" class="sidebar-link">数据处理</a></li><li><a href="/机器学习/机器学习.html" class="active sidebar-link">ML入门</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#模型的评估与选择" class="sidebar-link">模型的评估与选择</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#多个feather-map的作用是什么" class="sidebar-link">多个feather map的作用是什么？</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#卷积核的运算过程" class="sidebar-link">卷积核的运算过程</a></li></ul></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#metrics" class="sidebar-link">metrics：</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#model保存与读取" class="sidebar-link">model保存与读取</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#三通道图像处理" class="sidebar-link">三通道图像处理</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#反向传播算法-bp算法" class="sidebar-link">反向传播算法（BP算法）</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#构架网络总原则" class="sidebar-link">构架网络总原则</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#batch-size" class="sidebar-link">Batch_size</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#batch-和-epoch" class="sidebar-link">Batch 和 epoch</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#数据标准化" class="sidebar-link">数据标准化</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#batch-normalization-批标准化" class="sidebar-link">Batch Normalization  批标准化</a></li></ul></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#tf-data" class="sidebar-link">tf.data</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#cnn" class="sidebar-link">CNN</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#rnn-循环神经网络" class="sidebar-link">RNN 循环神经网络</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#lstm-长短记忆神经网络" class="sidebar-link">LSTM 长短记忆神经网络</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#文本序列的特征提取" class="sidebar-link">文本序列的特征提取</a></li></ul></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#gru" class="sidebar-link">GRU</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#双向rnn" class="sidebar-link">双向RNN</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#注意力机制" class="sidebar-link">注意力机制</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#encoder-decoder框架" class="sidebar-link">Encoder-Decoder框架</a></li></ul></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#微调" class="sidebar-link">微调</a></li><li class="sidebar-sub-header"><a href="/机器学习/机器学习.html#常见的预训练模型" class="sidebar-link">常见的预训练模型</a></li></ul></li><li><a href="/机器学习/机器学习数学基础.html" class="sidebar-link">机器学习数学基础</a></li><li><a href="/机器学习/激活函数.html" class="sidebar-link">激活函数</a></li><li><a href="/机器学习/统计机器学习.html" class="sidebar-link">统计机器学习</a></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>MachineLearningNotes-master</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>深度学习</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>硬件设计</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>算法与数据结构</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>编程语言</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>联邦学习</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>软件开发</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="ml入门"><a href="#ml入门" class="header-anchor">#</a> ML入门</h1> <p><img src="https://s2.loli.net/2022/10/05/IEA69RFhn2uMJQB.png" alt="截图"></p> <h1 id="杂"><a href="#杂" class="header-anchor">#</a> 杂</h1> <blockquote><p>loc函数：通过行索引 &quot;Index&quot; 中的具体值来取行数据（如取&quot;Index&quot;为&quot;A&quot;的行）
iloc函数：通过行号来取行数据（如取第二行的数据）</p></blockquote> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment">#取索引为'a'的行</span>
In<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span>
Out<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
A    <span class="token number">0</span>
B    <span class="token number">1</span>
C    <span class="token number">2</span>
D    <span class="token number">3</span>
 
<span class="token comment">#取第一行数据，索引为'a'的行就是第一行，所以结果相同</span>
In<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token comment">#数据是从0下标开始的</span>
Out<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
A    <span class="token number">0</span>
B    <span class="token number">1</span>
C    <span class="token number">2</span>
D    <span class="token number">3</span>
</code></pre></div><p><img src="https://s2.loli.net/2022/10/05/AbcJHLN5Fs9zurZ.png" alt="截图"></p> <p>回归问题，loss选择’mse‘ 均方差误差损失函数 ； metrics 选择 ’mae‘  （mean absolute error平均绝对误差）</p> <p>MSE均方误差 比 MAE平均绝对误差  对于异常的惩罚程度更高</p> <p>one-hot编码 它只对变量的值进行表示，各个变量之间没有大小关系，避免了像（1,2,3,4这种自然顺序的缺陷）</p> <h1 id="机器学习"><a href="#机器学习" class="header-anchor">#</a> 机器学习</h1> <p>one-hot编码：</p> <div class="language-python extra-class"><pre class="language-python"><code>性别：<span class="token punctuation">[</span><span class="token string">&quot;male&quot;</span>，<span class="token string">&quot;female&quot;</span><span class="token punctuation">]</span>
地区：<span class="token punctuation">[</span><span class="token string">&quot;Europe&quot;</span>，<span class="token string">&quot;US&quot;</span>，<span class="token string">&quot;Asia&quot;</span><span class="token punctuation">]</span>
浏览器：<span class="token punctuation">[</span><span class="token string">&quot;Firefox&quot;</span>，<span class="token string">&quot;Chrome&quot;</span>，<span class="token string">&quot;Safari&quot;</span>，<span class="token string">&quot;Internet Explorer&quot;</span><span class="token punctuation">]</span>


<span class="token punctuation">[</span><span class="token string">&quot;male&quot;</span>，<span class="token string">&quot;US&quot;</span>，<span class="token string">&quot;Internet Explorer&quot;</span><span class="token punctuation">]</span>的one<span class="token operator">-</span>hot编码是<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>
</code></pre></div><p>训练样本的“独立同分布”性越好，训练模型的泛化能力越好。</p> <p>样本越多，泛化能力越好。</p> <p>分类：预测的是离散值</p> <div class="language- extra-class"><pre class="language-text"><code>    性能度量：错误率与精度
</code></pre></div><p><img src="https://s2.loli.net/2022/10/05/RlCtIGsKYJwcdWf.png" alt="截图"></p> <p>回归：预测的是连续值</p> <div class="language- extra-class"><pre class="language-text"><code>    性能度量：均方误差MSE  
</code></pre></div><p><img src="https://s2.loli.net/2022/10/05/QbCEVtw6xc4gDi5.png" alt="截图"></p> <ul><li>监督学习</li></ul> <ol><li>分类</li> <li>回归</li></ol> <ul><li>无监督学习</li></ul> <ol><li>聚类</li></ol> <ul><li>半监督学习</li></ul> <h2 id="模型的评估与选择"><a href="#模型的评估与选择" class="header-anchor">#</a> 模型的评估与选择</h2> <p>留出法：训练集：验证集 = 2/3 ~ 4/5</p> <p>交叉验证法：</p> <p><img src="https://s2.loli.net/2022/10/05/pwoWBDclLJaTAjv.png" alt="截图"></p> <p>查准率和召回率：</p> <p><img src="https://s2.loli.net/2022/10/05/Kdyz2uG6U5Biw9E.png" alt="截图"></p> <p>P：正确的占预测结果为正确的比例</p> <p>R：正确的占实际结果为正确的比例</p> <p>F1度量：</p> <p><img src="https://s2.loli.net/2022/10/05/XeyvurGPCxYISAn.png" alt="截图"></p> <p><img src="https://s2.loli.net/2022/10/05/muT1jCwf647DQne.png" alt="截图"></p> <p>对于分类问题中的阈值定义：</p> <div class="language- extra-class"><pre class="language-text"><code>    在不同的应用任务中，我们可根据任务需求来采用不同的截断点，例如若我们更重视&quot;查准率&quot;，则可选择排序中靠前的位置进行截断;若更重视&quot;查全率&quot;，则可选择靠后的位置进行截断.
</code></pre></div><p>关于CNN的卷积详细过程可以参考这片博客:</p> <p>https://blog.csdn.net/xys430381_1/article/details/82529397</p> <h3 id="多个feather-map的作用是什么"><a href="#多个feather-map的作用是什么" class="header-anchor">#</a> 多个feather map的作用是什么？</h3> <div class="language- extra-class"><pre class="language-text"><code>    在卷积神经网络中，我们希望用一个网络模拟视觉通路的特性，分层的概念是自底向上构造简单到复杂的神经元。楼主关心的是同一层，那就说说同一层。

    我们希望构造一组基，这组基能够形成对于一个事物完备的描述，例如描述一个人时我们通过描述身高/体重/相貌等，在卷积网中也是如此。在同一层，我们希望得到对于一张图片多种角度的描述，**具体来讲就是用多种不同的卷积核对图像进行卷，得到不同核**（这里的核可以理解为描述）上的响应，作为图像的特征。他们的联系在于形成图像在同一层次不同基上的描述。
</code></pre></div><h3 id="卷积核的运算过程"><a href="#卷积核的运算过程" class="header-anchor">#</a> 卷积核的运算过程</h3> <p>例如输入224x224x3（rgb三通道），输出是32位深度，卷积核尺寸为5x5。</p> <p>那么我们需要32个卷积核，每一个的尺寸为5x5x3（最后的3就是原图的rgb位深3），每一个卷积核的每一层是5x5（共3层）分别与原图的每层224x224卷积，然后将得到的三张新图叠加（算术求和），变成一张新的feature map。 每一个卷积核都这样操作，就可以得到32张新的feature map了。  也就是说：</p> <p>不管输入图像的深度为多少，经过一个卷积核（filter），最后都通过下面的公式变成一个深度为1的特征图。不同的filter可以卷积得到不同的特征，也就是得到不同的feature map。。。</p> <h2 id="metrics"><a href="#metrics" class="header-anchor">#</a> metrics：</h2> <p>model.compile(optimizer='Adam',
loss='mse',
metrics=['accuracy'])</p> <p>1) 如果真实值标签和预测值都是具体的index值（如真值序列 = [1, 1, 1], y_pred=[0, 1, 1]）时，直接使用accuracy评价函数就可以满足大部分情况。（即非常简单的应用场景，数据集当中有明确的分类信息label）</p> <p>2) 如果真实值标签是具体的index值，而预测值是向量形式，且问题为多分类问题（如真实值= [1, 1, 1], 预测序列=[[0.2, 0.3, 0.5], [0.45, 0.2, 0.35], [0, 0.24, 0.78]]）时，用sparse_categorical_accuracy评价函数可以解决问题。</p> <p>3）如果真实值标签是one-hot形式，而预测值是向量形式（如真实值 = [[0, 1, 0], [0, 0, 1], [1, 0, 0]], 预测值= [[0.52, 0.33, 0.15], [0.9, 0.1, 0], [0, 0.4, 0.6]]）时，用categorical_accuracy评价函数就可以。</p> <h2 id="model保存与读取"><a href="#model保存与读取" class="header-anchor">#</a> model保存与读取</h2> <p>保存了</p> <p>1、权重值  2、模型配置（架构）  3、优化器配置</p> <div class="language-python extra-class"><pre class="language-python"><code>model<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">'./model.h5'</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> load_model<span class="token punctuation">(</span><span class="token string">'model.h5'</span><span class="token punctuation">)</span>
modelsummary<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_image<span class="token punctuation">,</span>test_label <span class="token punctuation">,</span>verbose <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span> 
<span class="token comment">#输出的是[loss，accuracy]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="三通道图像处理"><a href="#三通道图像处理" class="header-anchor">#</a> 三通道图像处理</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_of_instances<span class="token punctuation">)</span><span class="token punctuation">:</span>
    img_name<span class="token punctuation">,</span> age <span class="token operator">=</span> lines<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span>
    y_train<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>age<span class="token punctuation">)</span><span class="token punctuation">)</span>

    im <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;imgdata\\&quot;</span><span class="token operator">+</span>img_name<span class="token punctuation">)</span>  <span class="token comment">##文件存在的路径</span>
    im <span class="token operator">=</span> im<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    img <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>im<span class="token punctuation">)</span>
    img <span class="token operator">=</span> img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">/</span><span class="token number">255</span>
    x_train<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">)</span>

x_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
线性回归的案例
</code></pre></div><p>输出损失函数图像</p> <div class="language- extra-class"><pre class="language-text"><code>print(history.history.keys())
plt.plot(history.epoch , history.history.get('loss'))
plt.show()
</code></pre></div><p><img src="https://s2.loli.net/2022/10/05/EOQsRhX917pD3Ny.png" alt="截图"></p> <p>如果loss-epoch函数图像的曲线上下震荡，说明学习率可能不太合适！</p> <div class="language-python extra-class"><pre class="language-python"><code>model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span>
评估测试集
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>train_label_onehot <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>train_label<span class="token punctuation">)</span>

多分类数据标签转为One<span class="token operator">-</span>hot编码
</code></pre></div><h2 id="反向传播算法-bp算法"><a href="#反向传播算法-bp算法" class="header-anchor">#</a> 反向传播算法（BP算法）</h2> <p>如何根据损失函数来调节参数呢？</p> <p>答案：BP算法！从后往前传递误差，修改参数。</p> <h2 id="构架网络总原则"><a href="#构架网络总原则" class="header-anchor">#</a> 构架网络总原则</h2> <blockquote><p>一、增大网络容量,直到过拟合
二、采取措施抑制过拟合
三、继续增大网络容量,直到过拟合</p></blockquote> <h2 id="batch-size"><a href="#batch-size" class="header-anchor">#</a> Batch_size</h2> <blockquote><p><strong>可不可以选择一个适中的 Batch_Size 值呢？</strong>
当然可以，这就是批梯度下降法（Mini-batches Learning）。因为如果数据集足够充分，那么用一半（甚至少得多）的数据训练算出来的梯度与用全部数据训练出来的梯度是几乎一样的。</p></blockquote> <h2 id="batch-和-epoch"><a href="#batch-和-epoch" class="header-anchor">#</a> Batch 和 epoch</h2> <p>最后，让我们用一个小例子来说明这一点。</p> <p>假设您有一个包含200个样本（数据行）的数据集，并且您选择的Batch大小为5和1,000个Epoch。</p> <p>这意味着数据集将分为40个Batch，每个Batch有5个样本。每批五个样品后，模型权重将更新。</p> <p>这也意味着一个epoch将涉及40个Batch或40个模型更新。</p> <p>有1000个Epoch，模型将暴露或传递整个数据集1,000次。在整个培训过程中，总共有40,000Batch。</p> <h2 id="数据标准化"><a href="#数据标准化" class="header-anchor">#</a> 数据标准化</h2> <ul><li>标准化</li></ul> <p><strong>将数据减均值除方差</strong>  （均值为0 ，方差为1）</p> <p>不对 label（y值）做标准化</p> <div class="language-python extra-class"><pre class="language-python"><code>mean <span class="token operator">=</span> train_x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment">#均值</span>
std <span class="token operator">=</span> train_x<span class="token punctuation">.</span>std<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>   <span class="token comment">#方差</span>

train_x <span class="token operator">=</span> <span class="token punctuation">(</span>test_x <span class="token operator">-</span> mean<span class="token punctuation">)</span><span class="token operator">/</span>std  <span class="token comment">#数据标准化  减均值 除方差</span>


也可以用sklearn 中的 StandardScaler类 来实现特征缩放
RobustScaler 也有更好鲁棒性
</code></pre></div><ul><li>归一化</li></ul> <p><strong>将数据变为0-1之间</strong></p> <h3 id="batch-normalization-批标准化"><a href="#batch-normalization-批标准化" class="header-anchor">#</a> Batch Normalization  批标准化</h3> <blockquote><p>不仅在将数据输入模型之前进行数据标准化</p> <p>而且在每一次网络变化后的数据也进行数据标准化</p></blockquote> <p>解决：梯度消失和梯度爆炸问题 （以sigmoid函数为例，一个是数据都在右端的情况，一个是都在0附近的情况）</p> <p>好处：</p> <ol><li>抑制过拟合、提高模型泛化能力、具有正则化的效果</li> <li>加快收敛、允许使用更大的学习速率</li> <li>允许使用更深的网络</li></ol> <p>通常加在卷积层之后</p> <div class="language-python extra-class"><pre class="language-python"><code>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Batchnormalization<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p>BN层一般放在线性层或卷积层后面，激活函数前面，作用如下：</p> <p>1.加快网络收敛；
因为每层的数据都转换为同一的分布，这样会加快训练速度。</p> <p>2.防止梯度爆炸和梯度消失；
因为BN会使非线性变换函数的输入值落入对输入比较敏感的区域。</p> <p>3.防止过拟合，提升泛化能力。
因为BN求均值和方差是基于同一个batch内的样本，使网络不会朝一个方向学习。</p> <p><img src="https://s2.loli.net/2023/02/19/H58GT3theIqPBdp.png" alt="image-20230219230437176"></p> <h2 id="tf-data"><a href="#tf-data" class="header-anchor">#</a> tf.data</h2> <div class="language-python extra-class"><pre class="language-python"><code>dataset_images <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span>train_images<span class="token punctuation">)</span>
dataset_labels <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span>train_labels<span class="token punctuation">)</span>
dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span><span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token punctuation">(</span>dataset_images<span class="token punctuation">,</span> dataset_labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> steps_per_epoch<span class="token operator">=</span>steps_per_epoch<span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>也可以这么写
dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>train_images<span class="token punctuation">,</span>train_labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> steps_per_epoch<span class="token operator">=</span>steps_per_epoch<span class="token punctuation">)</span>
</code></pre></div><p><strong>推荐使用tf.data来构建输入，速度快！！！ 第一次遇到数据就会将数据缓存到硬盘中，第二轮epoch时直接从硬盘缓存区取。</strong></p> <h2 id="cnn"><a href="#cnn" class="header-anchor">#</a> CNN</h2> <p>核心思想：把输入的图像数据，<strong>变小变厚</strong></p> <div class="language-python extra-class"><pre class="language-python"><code>train_images <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>train_images <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
加了一维度
从（<span class="token number">60000</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span>） <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>》 （<span class="token number">60000</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span> <span class="token punctuation">,</span><span class="token number">1</span>）
</code></pre></div><p>池化层：减小矩阵的size，提取关键特征---&gt;使得视野变大</p> <ul><li><strong>输入数据处理</strong> <blockquote><p>0、读取路径，加载图片</p> <p>1、需要将图片转化为数据，进行decode解码</p> <p>2、转换数据类型</p> <p>3、对数据进行标准化，化为0-1之间的数</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">load_and_preprocess_image</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    image <span class="token operator">=</span> tf<span class="token punctuation">.</span>io<span class="token punctuation">.</span>read_file<span class="token punctuation">(</span>path<span class="token punctuation">)</span>
       <span class="token comment">#image = tf.image.decode_image(image, channels=3) #没有shape</span>
    image <span class="token operator">=</span> tf<span class="token punctuation">.</span>image<span class="token punctuation">.</span>decode_jpeg<span class="token punctuation">(</span>image<span class="token punctuation">,</span> channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment">#处理jpeg图像</span>
    image <span class="token operator">=</span> tf<span class="token punctuation">.</span>image<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#改变图片的大小 为 特定大小</span>
    image <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>image<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    image <span class="token operator">=</span> image<span class="token operator">/</span><span class="token number">255.0</span>  <span class="token comment"># normalize to [0,1] range  </span>
    <span class="token keyword">return</span> image
</code></pre></div></blockquote></li></ul> <p>将数据处理成tf.data</p> <div class="language-python extra-class"><pre class="language-python"><code>image_label_ds <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span><span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token punctuation">(</span>image_ds<span class="token punctuation">,</span> label_ds<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><ul><li><strong>构建卷积模型</strong><div class="language-python extra-class"><pre class="language-python"><code>model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment">#顺序模型</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>GlobalAveragePooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#类似于Flatten的作用，对于层进行取平均（一个层---&gt;一个数）</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#二分类</span>
                                                           <span class="token comment">#softmax 多分类</span>
      
<span class="token comment">#一般我们卷积核的个数都是*2递增</span>

model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>
              loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span>
              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> 
                    epochs<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span>
                    steps_per_epoch<span class="token operator">=</span>steps_per_epoch<span class="token punctuation">,</span> 
                    validation_data<span class="token operator">=</span>test_data<span class="token punctuation">,</span>
                    validation_steps<span class="token operator">=</span>validation_steps<span class="token punctuation">)</span>
</code></pre></div></li></ul> <p>可视化：</p> <div class="language-python extra-class"><pre class="language-python"><code>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> history<span class="token punctuation">.</span>history<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'acc'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'acc'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> history<span class="token punctuation">.</span>history<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'val_acc'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'val_acc'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p><img src="https://s2.loli.net/2022/10/05/qwrcgLCaP1ue4Uv.png" alt="截图"></p> <div class="language-python extra-class"><pre class="language-python"><code>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> history<span class="token punctuation">.</span>history<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> history<span class="token punctuation">.</span>history<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'val_loss'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p><img src="https://s2.loli.net/2022/10/05/RLYam6P3kzMCAjr.png" alt="截图"></p> <p><strong>将一个特征转换为一个向量</strong></p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment">#vocab_size:字典大小</span>
<span class="token comment">#embedding_dim:本层的输出大小，也就是生成的embedding的维数</span>
<span class="token comment">#input_length:输入数据的维数，因为输入数据会做padding处理，所以一般是定义的max_length</span>
keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> input_length <span class="token operator">=</span> max_length<span class="token punctuation">)</span>

</code></pre></div><h2 id="rnn-循环神经网络"><a href="#rnn-循环神经网络" class="header-anchor">#</a> RNN 循环神经网络</h2> <p><strong>序列问题</strong></p> <p>序列数据</p> <blockquote><p>输入：三维序列  （batch ， 词的长度 ， 向量化后的长度 ）</p> <p>输出：二维输出   是一种评价</p></blockquote> <p>一个序列的当前的输出与前面的输出有关</p> <p>每一次训练，输入层经过隐藏层不仅会产生结果输出（output），而且会产生一个状态输出（state）。这个状态输出会和下一次的输入一起进入隐藏层 ，产生下一次的结果以及下一次的状态输出，以此形成循环。</p> <p>最后一次输出以及包含了前面所有数据的特点，可以将其结果直接用于全连接层。</p> <p><img src="https://s2.loli.net/2022/10/05/S7E5xOZ9p34TVru.png" alt="截图"></p> <h2 id="lstm-长短记忆神经网络"><a href="#lstm-长短记忆神经网络" class="header-anchor">#</a> LSTM 长短记忆神经网络</h2> <p>解决：梯度消失和梯度爆炸问题</p> <p>是一种RNN的变种，可以学习长期的依赖信息</p> <p>是RNN的代表</p> <p>原理：通过门对通过的信息进行控制（通过、完全通过、不通过）</p> <div class="language-python extra-class"><pre class="language-python"><code>model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span>train_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#默认activation 是 tanh ，比较好</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

其中单层LSTM网络，最后输出的是一个一维的结果（二维的值，还有一维是batch）
当我们用两层及以上的LSTM时，使用return_sequences ，他会记录每一次的输出数据而不仅仅是最后一次
但是最后一个LSTM我们不需要设定return_sequences！！！
</code></pre></div><p><strong>LSTM层的优化</strong></p> <p>和CNN中堆叠卷积层的思路一样（堆叠10层，就能达到90%的预测效果）</p> <p>①我们这里堆叠LSTM网络</p> <p>②在训练中降低学习速率：在前期快速接近最小值，后期慢慢靠近。</p> <div class="language-python extra-class"><pre class="language-python"><code>model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span>train_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#这里不需要设定return_sequences</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token string">'mae'</span><span class="token punctuation">)</span>

learning_rate_reduction <span class="token operator">=</span> keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>ReduceLROnPlateau<span class="token punctuation">(</span>monitor<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span> patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> factor<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> min_lr<span class="token operator">=</span><span class="token number">0.00001</span><span class="token punctuation">)</span>
<span class="token comment">#监测指标：val_loss  在3个epotch后降低   降低比例 0.5</span>
history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span>
                    batch_size <span class="token operator">=</span> <span class="token number">128</span><span class="token punctuation">,</span>
                    epochs<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
                    validation_data<span class="token operator">=</span><span class="token punctuation">(</span>test_x<span class="token punctuation">,</span> test_y<span class="token punctuation">)</span><span class="token punctuation">,</span>
                    callbacks<span class="token operator">=</span><span class="token punctuation">[</span>learning_rate_reduction<span class="token punctuation">]</span><span class="token punctuation">)</span>
                    
model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_x <span class="token punctuation">,</span>test_y <span class="token punctuation">,</span> verbose <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="文本序列的特征提取"><a href="#文本序列的特征提取" class="header-anchor">#</a> 文本序列的特征提取</h3> <ul><li><p>词袋模型</p> <p>类似于onehot编码 [0,1,0,1,1,0,0,0,0,1]</p> <p>从而可以计算向量之间的距离</p> <p>包含多0元素的高维向量称为 <strong>稀疏向量</strong></p> <p>如何降低特征空间的维度？</p> <p>1、停用词过滤</p> <p>2、全部转为小写</p> <p>3、次干提取、词形还原</p></li> <li><p>词向量</p></li></ul> <h2 id="gru"><a href="#gru" class="header-anchor">#</a> GRU</h2> <p>LSTM的变种</p> <p>结构更简单、计算少、效果和LSTM相差无几</p> <p><strong>Embedding : 把文本映射为一个密集向量（区别于one-hot编码）</strong></p> <p>Embedding层只能作为模型的第一层</p> <div class="language-python extra-class"><pre class="language-python"><code>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> embeddings_initializer<span class="token operator">=</span><span class="token string">'uniform'</span><span class="token punctuation">,</span> 
                                  embeddings_regularizer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> activity_regularizer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                                  embeddings_constraint<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                                  mask_zero<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> input_length<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
input_dim：大或等于<span class="token number">0</span>的整数，字典长度，即输入数据最大下标<span class="token operator">+</span><span class="token number">1</span>
output_dim：大于<span class="token number">0</span>的整数，代表全连接嵌入的维度
input_length：当输入序列的长度固定时，该值为其长度。
</code></pre></div><p>行大小为词的数目50,000，列大小为词向量的维度(通常取128或300)</p> <p>单词表大小为50,000，词向量的维度为300，所以Embedding的参数 input_dim=50,000，output_dim=300</p> <p><img src="https://s2.loli.net/2022/10/05/Iw3ALbzl9fn6upZ.png" alt="截图"></p> <p>循环神经网络示例：</p> <div class="language-python extra-class"><pre class="language-python"><code>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>max_word<span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> input_length<span class="token operator">=</span>maxlen<span class="token punctuation">)</span><span class="token punctuation">)</span>   
<span class="token comment">#max_word也就是字典中单词的总个数</span>
<span class="token comment">#50  也就是映射后的密集向量的长度  可以自己随便写（自己定义）</span>
<span class="token comment"># input_length  输入文本的长度 即单条数据集的文本长度</span>

model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment">#越大越过拟合  64个神经单元</span>

model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#sigmoid二分类常用！</span>
                                                  <span class="token comment">#softmax多分类常用！</span>

_________________________________________________________________
Layer <span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">)</span>                 Output Shape              Param <span class="token comment">#   </span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
embedding <span class="token punctuation">(</span>Embedding<span class="token punctuation">)</span>        <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span>            <span class="token number">355050</span>    
_________________________________________________________________
lstm <span class="token punctuation">(</span>LSTM<span class="token punctuation">)</span>                  <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>                <span class="token number">29440</span>     
_________________________________________________________________
dense <span class="token punctuation">(</span>Dense<span class="token punctuation">)</span>                <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>                 <span class="token number">65</span>        
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
Total params<span class="token punctuation">:</span> <span class="token number">384</span><span class="token punctuation">,</span><span class="token number">555</span>
Trainable params<span class="token punctuation">:</span> <span class="token number">384</span><span class="token punctuation">,</span><span class="token number">555</span>
Non<span class="token operator">-</span>trainable params<span class="token punctuation">:</span> <span class="token number">0</span>
_________________________________________________________________

model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>
              loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span>  <span class="token comment">#二分类交叉熵损失函数</span>
              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>


history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data_ok<span class="token punctuation">,</span> data<span class="token punctuation">.</span>review<span class="token punctuation">.</span>values<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
<span class="token comment">#validation_split 是指将数据集的20%作为验证集进行训练 </span>
</code></pre></div><h2 id="双向rnn"><a href="#双向rnn" class="header-anchor">#</a> 双向RNN</h2> <h2 id="注意力机制"><a href="#注意力机制" class="header-anchor">#</a> 注意力机制</h2> <h3 id="encoder-decoder框架"><a href="#encoder-decoder框架" class="header-anchor">#</a> Encoder-Decoder框架</h3> <p>如果Source是中文句子，Target是英文句子，那么这就是解决机器翻译问题的Encoder-Decoder框架；如果Source是一篇文章，Target是概括性的几句描述语句，那么这是文本摘要的Encoder-Decoder框架；如果Source是一句问句，Target是一句回答，那么这是问答系统或者对话机器人的Encoder-Decoder框架。由此可见，在文本处理领域，Encoder-Decoder的应用领域相当广泛。</p> <p>Encoder-Decoder框架不仅仅在文本领域广泛使用，在语音识别、图像处理等领域也经常使用。比如对于语音识别来说，图2所示的框架完全适用，区别无非是Encoder部分的输入是语音流，输出是对应的文本信息；而对于“图像描述”任务来说，Encoder部分的输入是一副图片，Decoder的输出是能够描述图片语义内容的一句描述语。一般而言，文本处理和语音识别的Encoder部分通常采用RNN模型，图像处理的Encoder一般采用CNN模型。</p> <p><a href="https://" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/malefactor/article/details/78767781?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-78767781.nonecase&amp;spm=1018.2226.3001.4187<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>讲的很通俗易懂</p> <p><img src="https://s2.loli.net/2022/10/05/hPFm4WHqciO1AMJ.png" alt="截图"></p> <div class="language- extra-class"><pre class="language-text"><code>我们可以这样来看待Attention机制（参考图9）：将Source中的构成元素想象成是由一系列的&lt;Key,Value&gt;数据对构成，此时给定Target中的某个元素Query，通过计算Query和各个Key的相似性或者相关性，得到每个Key对应Value的权重系数，然后对Value进行加权求和，即得到了最终的Attention数值。所以本质上Attention机制是对Source中元素的Value值进行加权求和，而Query和Key用来计算对应Value的权重系数。即可以将其本质思想改写为如下公式：
</code></pre></div><p><img src="https://s2.loli.net/2022/10/05/hPO2ZJQyYjlECSo.png" alt="截图"></p> <p><img src="https://s2.loli.net/2022/10/05/CaTEZmOvxjuh76V.png" alt="截图"></p> <p>至于Attention机制的<strong>具体计算过程</strong>，如果对目前大多数方法进行抽象的话，可以将其归纳为两个过程：第一个过程是根据Query和Key计算权重系数，第二个过程根据权重系数对Value进行加权求和。而第一个过程又可以细分为两个阶段：第一个阶段根据Query和Key计算两者的相似性或者相关性；第二个阶段对第一阶段的原始分值进行归一化处理；这样，可以将Attention的计算过程抽象为如图10展示的三个阶段。</p> <p><img src="https://s2.loli.net/2022/10/05/5lod8vAQgxD2zrV.png" alt="截图"></p> <h1 id="迁移学习"><a href="#迁移学习" class="header-anchor">#</a> 迁移学习</h1> <p><strong>用预训练好的网络来实现</strong></p> <p>VGG16（16层）   VGG19（19层 ）   图卷积   堆叠层数</p> <p>缺点：网络weight巨大，训练慢。</p> <p>卷积基：对于图片特征的高效提取</p> <p>一般来说分类器都是自己写</p> <p>一般设置卷积基的模型weight设置不可训练**（冻结）**</p> <div class="language-python extra-class"><pre class="language-python"><code>covn_base<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">False</span>

global_average_pooling2d层 可以当做flatten层来用，效果也很好！！！
</code></pre></div><p><img src="https://s2.loli.net/2022/10/05/z75pHy61BFKWVij.png" alt="截图"></p> <h2 id="微调"><a href="#微调" class="header-anchor">#</a> 微调</h2> <ol><li>在预训练卷积基上添加自定义层</li> <li>冻结卷积基</li> <li>训练添加的分类层</li> <li>解冻卷积基的一部分层进行微调</li></ol> <div class="language-python extra-class"><pre class="language-python"><code>covn_base<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">True</span>
</code></pre></div><p><img src="https://s2.loli.net/2022/10/05/w216vWSoGelcgYO.png" alt="截图"></p> <p><img src="https://s2.loli.net/2022/10/05/FCnDNMP4zvfBGr9.png" alt="截图"></p> <p>只让卷积基的倒数三层可以进行训练</p> <p><strong>用更低的学习速率</strong>，进行下探！！！</p> <p>前面训练的12epoch，现在打算在进行训练10epoch，从第13epoch开始训练</p> <h2 id="常见的预训练模型"><a href="#常见的预训练模型" class="header-anchor">#</a> 常见的预训练模型</h2> <p><img src="https://s2.loli.net/2022/10/05/FjMl8XaB5VY24ks.png" alt="截图"></p> <p><img src="https://s2.loli.net/2022/10/05/I4fuwWmv2QcGPY9.png" alt="截图"></p> <h1 id="tensorboard的使用"><a href="#tensorboard的使用" class="header-anchor">#</a> Tensorboard的使用</h1> <h1 id="多输出模型实例"><a href="#多输出模型实例" class="header-anchor">#</a> 多输出模型实例</h1> <h1 id="杂-2"><a href="#杂-2" class="header-anchor">#</a> 杂</h1> <p>线性模型：一般都可以用y=w0+w1x1+w2x2+....+wnxn；</p> <p>来表示</p> <p>如果y的值是连续的，那就是线性回归，如果是离散值（枚举类型），那就是分类模型；</p> <p>对一些非线性模型：例如椭圆，非规则的线，等等，其函数有</p> <p>y=w0+sin（w1）x+cos（w2）x+expw3x3 。。。</p> <p>需要使用带核函数的SVM，神经网络等更复杂的模型。</p> <p>线性回归，代价函数  是 <strong>最小二乘法</strong></p> <p>梯度下降法</p> <p><img src="https://s2.loli.net/2022/10/05/PJrki9cF4ty3qYb.png" alt="截图"></p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">最后更新时间:</span> <span class="time">1 分钟前</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/机器学习/数据处理.html" class="prev">
        数据处理
      </a></span> <span class="next"><a href="/机器学习/机器学习数学基础.html">
        机器学习数学基础
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.6d855320.js" defer></script><script src="/assets/js/2.d4ff5c60.js" defer></script><script src="/assets/js/52.d1cb790e.js" defer></script>
  </body>
</html>
